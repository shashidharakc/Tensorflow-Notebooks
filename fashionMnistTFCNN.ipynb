{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Mnist using CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all the required data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-e6a4ec5a3136>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dataSets/fashionMnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dataSets/fashionMnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../dataSets/fashionMnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../dataSets/fashionMnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../dataSets/fashionMnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some python assignments so the tensorflow graph looks nice, like number of epochs, number of output classes, input vector size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 28\n",
    "image_width = 28\n",
    "num_input = image_height * image_width\n",
    "num_classes = 10\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders for inpputs to feed in data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Placeholder = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y_Placeholder = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution forward pass : Initialize / declare convolution layers and respective paramaters.\n",
    "Begin by reshaping the imput vector to *****\n",
    "\n",
    "As this is not optimized, lets initilaize both the convolution layers and corresponding pooling layers lookalike, with input and filters size as difference, i.e the first convolution layer being feed by reshaped input and output of first pool layer is feed to second convolution layer. Filter size for first convolution layer is set at 32 and second at 64.\n",
    "\n",
    "Rest the hypreparams of both convolution layer are initialize with similar way. Same goes for pooling layer, input for each being there respective convolution layer output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputReshape = tf.reshape(X_Placeholder, [-1,image_height,image_width,1])\n",
    "\n",
    "convolutionL1 = tf.layers.conv2d(inputs=inputReshape, filters=32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "poolL1 = tf.layers.max_pooling2d(inputs=convolutionL1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "convolutionL2 = tf.layers.conv2d(inputs=poolL1, filters=64, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "poolL2 = tf.layers.max_pooling2d(inputs=convolutionL2, pool_size=[2, 2], strides=2)\n",
    "poolFlat = tf.reshape(poolL2, [-1, 7 * 7 * 64])\n",
    "\n",
    "hidden = tf.layers.dense(inputs=poolFlat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(inputs=hidden, rate=0.5, training=True)\n",
    "output = tf.layers.dense(inputs=dropout, units=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we calculate the loss/ error from forward pass. Tensorflow will do the back prop for us(very nice of tensorflow) using Adamoptimizer(we can use other optimizers as well :)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(Y_Placeholder, output)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate predictions and accuracy to know how our model flares and display same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(Y_Placeholder, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingridients to train all our algo, creat a new session and for each epoch train for all data in minibatchs of 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training batch accuracy 0.7900000214576721\n",
      "Epoch 1, training batch accuracy 0.8500000238418579\n",
      "Testdata accuracy 0.839900016784668\n"
     ]
    }
   ],
   "source": [
    "m = 55000\n",
    "minibatch_size = 128\n",
    "num_minibatches = int(m / minibatch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for _ in range(num_minibatches):\n",
    "            input_batch, labels_batch = mnist.train.next_batch(100)\n",
    "            feed_dict = {X_Placeholder: input_batch, Y_Placeholder: labels_batch}\n",
    "            train_step.run(feed_dict=feed_dict)\n",
    "\n",
    "        train_accuracy = accuracy.eval(feed_dict=feed_dict)\n",
    "        print(\"Epoch {Epoch}, training batch accuracy {Accuracy}\".format(Epoch=epoch, Accuracy=train_accuracy))\n",
    "\n",
    "    X_test = mnist.test.images \n",
    "    y_test = mnist.test.labels\n",
    "\n",
    "    print(\"Testdata accuracy {CalculatedAccuracy}\".format(\n",
    "        CalculatedAccuracy=accuracy.eval(feed_dict={X_Placeholder: X_test, Y_Placeholder: y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
