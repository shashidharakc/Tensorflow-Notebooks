{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion Mnist using RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing required libraries/packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-6eed87af41d9>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dataSets/fashionMnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../dataSets/fashionMnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../dataSets/fashionMnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../dataSets/fashionMnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('../../dataSets/fashionMnist',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare some python assignments/constants, like number of epochs, number of output classes, input vector size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 28\n",
    "image_width = 28\n",
    "num_time_steps=28\n",
    "num_units=128\n",
    "num_input=28\n",
    "learning_rate=0.001\n",
    "num_classes=10\n",
    "minibatch_size=128\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin building TF Graph, by declaring input and output placeholders\n",
    "\n",
    "InputPlaceholder a tensor of rank three(3D) of shape batch size, number of time steps and number of inputs dimension. In our case number of time steps is 28, so is number of inputs dimension, 28. Each image with heigth and width being 28 * 28, is unrolled to time steps of 28 and dimension of imput at each time step 28 features(pixels in our case).\n",
    "\n",
    "OutputPlaceholder : is a tensor of rank two, with shape batch size and number of output classes, which is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_placeholder=tf.placeholder(tf.float32,[None,num_time_steps,num_input])\n",
    "Y_placeholder=tf.placeholder(tf.float32,[None,num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our LSTM model to tell, which of 10 class the give image belongs we need to consider only the output of last step which is 28th step. Here we delcare the weights and bias for the calculating same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_weights=tf.get_variable(\"Output_Weights\", [num_units,num_classes], initializer=tf.initializers.random_normal(seed=12))\n",
    "output_bias=tf.get_variable(\"Output_bias\", [num_classes], initializer=tf.initializers.random_normal(seed=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting inputs: We unstack the input data, so we can feed the data of each steps to its respective LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unstack=tf.unstack(X_placeholder ,num_time_steps,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_units : is the number of nodes of LSTM cell, Static_rnn is a simplest for of RNN we can use dynamic_rnn nothing stops us. Dynamic is used for input of different length's, in out case the length of input is static , with length of 28, not dynamic. \n",
    "\n",
    "The inputs argument accepts list of tensors of shape [batch_size,input_size].The length of this list is the number of time steps through which network is unrolled i.e. each element of this list corresponds to the input at respective time step of our unrolled network.\n",
    "\n",
    "The output generated by static_rnn is a list of tensors of shape [batch_size,num_units].The length of the list is number of time steps through which network is unrolled i.e. one output tensor for each time step.In this implementation we will only be concerned with output of the final time step as the prediction will be generated when all the rows of an image are supplied to RNN i.e. at the last time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer=tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "outputs,_=tf.contrib.rnn.static_rnn(lstm_layer,X_unstack,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider only the last output, another way to put this is model we are training/building is many to one, which is we feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=tf.add(tf.matmul(outputs[-1],output_weights),output_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code takes back its usual for, for calculating loss and runing optimizer, we used for DNN and CNN .. i.e calculate loss with softmax cross entropy , optimizer used is Adama Optimizer with learning rate of 0.0001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=Y_placeholder))\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(Y_placeholder,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a session for each epoch, train will all the data with a minibatch of size 128. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training batch accuracy 0.796875\n",
      "Epoch 1, training batch accuracy 0.875\n",
      "Testdata accuracy 0.8314999938011169\n"
     ]
    }
   ],
   "source": [
    "m = 60000\n",
    "num_minibatches = int(m / minibatch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epochs):\n",
    "        for _ in range(num_minibatches):\n",
    "            batch_x,batch_y=mnist.train.next_batch(batch_size=minibatch_size)\n",
    "            batch_x=batch_x.reshape((minibatch_size,num_time_steps,num_input))\n",
    "            sess.run(opt, feed_dict={X_placeholder: batch_x, Y_placeholder: batch_y})\n",
    "            \n",
    "        print(\"Epoch {Epoch}, training batch accuracy {Accuracy}\".format(\n",
    "            Epoch=epoch, Accuracy=sess.run(accuracy, feed_dict={X_placeholder: batch_x, Y_placeholder: batch_y})))\n",
    "\n",
    "    \n",
    "    X_test = mnist.test.images # X_test shape: [num_test, 28*28]\n",
    "    X_test = X_test.reshape((-1,num_time_steps,num_input))\n",
    "    y_test = mnist.test.labels\n",
    "    \n",
    "    print(\"Testdata accuracy {CalculatedAccuracy}\".format(\n",
    "        CalculatedAccuracy=accuracy.eval(feed_dict={X_placeholder: X_test, Y_placeholder: y_test})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
